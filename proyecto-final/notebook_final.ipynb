{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea550c2d",
   "metadata": {},
   "source": [
    "Lista de cosas por hacer:\n",
    "- [ ] Más análisis\n",
    "    - [x] Riqueza léxica\n",
    "    - [x] Que palabras prefieren\n",
    "    - [ ] Longitud media de frases\n",
    "    - [x] Longitud media de palabras\n",
    "    - [x] De todos los textos leidos, que palabras aparecen más, cuáles menos y en que tipo son más frecuentes.(ToDo: Está a medias)\n",
    "- [ ] Dividir dataset en 60/20/20 variados\n",
    "- [ ] Entrenarlo y evaluar su capacidad de deteccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580020c4-bdd1-475b-afa6-4e3bf8eaeac5",
   "metadata": {},
   "source": [
    "Comienzo de la práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a09d96c9-5ae2-4d9a-bb39-7d3ec651e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd #procesado del csv pasa E/S\n",
    "import matplotlib as plt #printeo\n",
    "import random #operaciones matematicas\n",
    "from metodos import * #importamos metodos para una mayor legibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee1392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/Temas.txt\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/notebook_final.ipynb\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/metodos.py\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/archive/AI_Human.csv\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/.ipynb_checkpoints/notebook_final-checkpoint.ipynb\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/__pycache__/metodos.cpython-310.pyc\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "for dirname, _, filenames in os.walk('/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28d92929-910d-40c3-ad20-0ebf319a24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv('/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/archive/AI_Human.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13e087b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos totales:  487235\n",
      "Humanos:  305797\n",
      "IA:  181438\n"
     ]
    }
   ],
   "source": [
    "datos_totales = (datos['generated']).count()\n",
    "datos_humanos = (datos['generated'] == 0.0).sum()\n",
    "print(\"Datos totales: \", datos_totales)\n",
    "print(\"Humanos: \", datos_humanos)\n",
    "print(\"IA: \", datos_totales - datos_humanos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d189d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token = nltk.word_tokenize(datos['text'][0])\n",
    "# nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7dda7dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA:  1000\n",
      "Humanos:  1000\n"
     ]
    }
   ],
   "source": [
    "tokens_ia = []\n",
    "tokens_human = []\n",
    "\n",
    "limit = 1000\n",
    "while True:\n",
    "    valor = random.randint(0, len(datos['text']))\n",
    "    token = nltk.word_tokenize(datos['text'][valor])\n",
    "\n",
    "    if datos['generated'][valor] == 1.0 and len(tokens_ia)<limit:\n",
    "        tokens_ia.append(token)\n",
    "    elif datos['generated'][valor] == 0.0 and len(tokens_human)<limit:\n",
    "        tokens_human.append(token)\n",
    "    if len(tokens_ia) == limit and len(tokens_human) == limit:\n",
    "        break\n",
    "\n",
    "print(\"IA: \", len(tokens_ia))\n",
    "print(\"Humanos: \", len(tokens_human))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61848e",
   "metadata": {},
   "source": [
    "Let's find the lexical richness of the AI texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3ef7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45421532496184"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_richness_ia = 0\n",
    "num = 0\n",
    "\n",
    "for i in range(0, len(tokens_ia)):\n",
    "    medium_richness_ia += lexical_richness(tokens_ia[i])\n",
    "    num += 1\n",
    "medium_richness_ia = medium_richness_ia/num\n",
    "medium_richness_ia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede1bc3",
   "metadata": {},
   "source": [
    "Let's find the lexical richness of the Human texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2bfdc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42450081929600764"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_richness_human = 0\n",
    "num = 0\n",
    "\n",
    "for i in range(0, len(tokens_human)):\n",
    "    #print(i, tokens_human[i])\n",
    "    medium_richness_human = lexical_richness(tokens_human[i])+medium_richness_human\n",
    "    num += 1\n",
    "\n",
    "\n",
    "medium_richness_human = medium_richness_human/num\n",
    "medium_richness_human"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7755cef",
   "metadata": {},
   "source": [
    "We're going to chech the performance and we're gonna display the accuracy of the tagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bef1211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First',\n",
       " 'impressions',\n",
       " 'are',\n",
       " 'the',\n",
       " 'initial',\n",
       " 'judgments',\n",
       " 'that',\n",
       " 'we',\n",
       " 'make',\n",
       " 'about',\n",
       " 'someone',\n",
       " 'based',\n",
       " 'on',\n",
       " 'their',\n",
       " 'appearance',\n",
       " ',',\n",
       " 'behavior',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'observable',\n",
       " 'cues',\n",
       " '.',\n",
       " 'While',\n",
       " 'these',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'can',\n",
       " 'be',\n",
       " 'useful',\n",
       " 'in',\n",
       " 'certain',\n",
       " 'situations',\n",
       " ',',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'always',\n",
       " 'accurate',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'influenced',\n",
       " 'by',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'factors',\n",
       " '.',\n",
       " 'In',\n",
       " 'this',\n",
       " 'essay',\n",
       " ',',\n",
       " 'I',\n",
       " 'will',\n",
       " 'explore',\n",
       " 'cow',\n",
       " 'differences',\n",
       " 'in',\n",
       " 'personality',\n",
       " ',',\n",
       " 'situations',\n",
       " ',',\n",
       " 'and',\n",
       " 'representation',\n",
       " 'impact',\n",
       " 'the',\n",
       " 'accuracy',\n",
       " 'of',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'of',\n",
       " 'others',\n",
       " '.',\n",
       " 'Ine',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'factors',\n",
       " 'that',\n",
       " 'can',\n",
       " 'impact',\n",
       " 'the',\n",
       " 'accuracy',\n",
       " 'of',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'is',\n",
       " 'personality',\n",
       " '.',\n",
       " 'People',\n",
       " 'with',\n",
       " 'different',\n",
       " 'personalities',\n",
       " 'may',\n",
       " 'became',\n",
       " 'in',\n",
       " 'different',\n",
       " 'ways',\n",
       " 'and',\n",
       " 'may',\n",
       " 'cave',\n",
       " 'different',\n",
       " 'attitudes',\n",
       " 'towards',\n",
       " 'certain',\n",
       " 'things',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'is',\n",
       " 'outgoing',\n",
       " 'and',\n",
       " 'extroverted',\n",
       " 'may',\n",
       " 'be',\n",
       " 'perceived',\n",
       " 'as',\n",
       " 'friendly',\n",
       " 'and',\n",
       " 'approachable',\n",
       " ',',\n",
       " 'while',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'is',\n",
       " 'introverted',\n",
       " 'and',\n",
       " 'reserved',\n",
       " 'may',\n",
       " 'be',\n",
       " 'perceived',\n",
       " 'as',\n",
       " 'cold',\n",
       " 'and',\n",
       " 'unfriendly',\n",
       " '.',\n",
       " 'These',\n",
       " 'personality',\n",
       " 'differences',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'inaccurate',\n",
       " 'first',\n",
       " 'impressions',\n",
       " ',',\n",
       " 'as',\n",
       " 'people',\n",
       " 'may',\n",
       " 'assume',\n",
       " 'that',\n",
       " 'someone',\n",
       " \"'s\",\n",
       " 'personality',\n",
       " 'is',\n",
       " 'fixed',\n",
       " 'and',\n",
       " 'unchanging',\n",
       " ',',\n",
       " 'when',\n",
       " 'in',\n",
       " 'reality',\n",
       " ',',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'fluid',\n",
       " 'and',\n",
       " 'dynamic',\n",
       " '.',\n",
       " 'Another',\n",
       " 'factor',\n",
       " 'that',\n",
       " 'can',\n",
       " 'impact',\n",
       " 'the',\n",
       " 'accuracy',\n",
       " 'of',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'is',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'in',\n",
       " 'WCCC',\n",
       " 'the',\n",
       " 'encounter',\n",
       " 'takes',\n",
       " 'place',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'is',\n",
       " 'friendly',\n",
       " 'and',\n",
       " 'approachable',\n",
       " 'in',\n",
       " 'a',\n",
       " 'casual',\n",
       " 'setting',\n",
       " 'may',\n",
       " 'appear',\n",
       " 'completely',\n",
       " 'different',\n",
       " 'in',\n",
       " 'a',\n",
       " 'professional',\n",
       " 'setting',\n",
       " '.',\n",
       " 'Similarly',\n",
       " ',',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'is',\n",
       " 'confident',\n",
       " 'and',\n",
       " 'assertive',\n",
       " 'in',\n",
       " 'one',\n",
       " 'situation',\n",
       " 'may',\n",
       " 'appear',\n",
       " 'anxious',\n",
       " 'and',\n",
       " 'unsure',\n",
       " 'in',\n",
       " 'another',\n",
       " '.',\n",
       " 'These',\n",
       " 'situational',\n",
       " 'differences',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'inaccurate',\n",
       " 'first',\n",
       " 'impressions',\n",
       " ',',\n",
       " 'as',\n",
       " 'people',\n",
       " 'may',\n",
       " 'assume',\n",
       " 'that',\n",
       " 'someone',\n",
       " \"'s\",\n",
       " 'behavior',\n",
       " 'is',\n",
       " 'consistent',\n",
       " 'across',\n",
       " 'different',\n",
       " 'situations',\n",
       " '.',\n",
       " 'Finally',\n",
       " ',',\n",
       " 'representation',\n",
       " 'can',\n",
       " 'also',\n",
       " 'impact',\n",
       " 'the',\n",
       " 'accuracy',\n",
       " 'of',\n",
       " 'first',\n",
       " 'impressions',\n",
       " '.',\n",
       " 'People',\n",
       " 'may',\n",
       " 'be',\n",
       " 'influenced',\n",
       " 'by',\n",
       " 'stereotypes',\n",
       " 'and',\n",
       " 'biases',\n",
       " 'that',\n",
       " 'they',\n",
       " 'cold',\n",
       " 'about',\n",
       " 'certain',\n",
       " 'groups',\n",
       " 'or',\n",
       " 'individuals',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'is',\n",
       " 'perceived',\n",
       " 'as',\n",
       " 'being',\n",
       " 'from',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'ethnic',\n",
       " 'or',\n",
       " 'cultural',\n",
       " 'background',\n",
       " 'may',\n",
       " 'be',\n",
       " 'assumed',\n",
       " 'to',\n",
       " 'cave',\n",
       " 'certain',\n",
       " 'characteristics',\n",
       " 'or',\n",
       " 'beliefs',\n",
       " ',',\n",
       " 'even',\n",
       " 'if',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'necessarily',\n",
       " 'align',\n",
       " 'with',\n",
       " 'those',\n",
       " 'assumptions',\n",
       " '.',\n",
       " 'These',\n",
       " 'biases',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'inaccurate',\n",
       " 'first',\n",
       " 'impressions',\n",
       " ',',\n",
       " 'as',\n",
       " 'people',\n",
       " 'may',\n",
       " 'make',\n",
       " 'assumptions',\n",
       " 'about',\n",
       " 'someone',\n",
       " 'based',\n",
       " 'on',\n",
       " 'their',\n",
       " 'appearance',\n",
       " 'or',\n",
       " 'background',\n",
       " ',',\n",
       " 'rather',\n",
       " 'can',\n",
       " 'getting',\n",
       " 'to',\n",
       " 'know',\n",
       " 'them',\n",
       " 'as',\n",
       " 'an',\n",
       " 'individual',\n",
       " '.',\n",
       " 'In',\n",
       " 'conclusion',\n",
       " ',',\n",
       " 'the',\n",
       " 'accuracy',\n",
       " 'of',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'can',\n",
       " 'be',\n",
       " 'impacted',\n",
       " 'by',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'factors',\n",
       " ',',\n",
       " 'including',\n",
       " 'personality',\n",
       " ',',\n",
       " 'situations',\n",
       " ',',\n",
       " 'and',\n",
       " 'representation',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'important',\n",
       " 'to',\n",
       " 'be',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'these',\n",
       " 'factors',\n",
       " 'and',\n",
       " 'to',\n",
       " 'strive',\n",
       " 'for',\n",
       " 'accuracy',\n",
       " 'and',\n",
       " 'objectivity',\n",
       " 'when',\n",
       " 'forming',\n",
       " 'first',\n",
       " 'impressions',\n",
       " 'of',\n",
       " 'others',\n",
       " '.',\n",
       " 'By',\n",
       " 'doing',\n",
       " 'so',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'avoid',\n",
       " 'making',\n",
       " 'assumptions',\n",
       " 'and',\n",
       " 'judgments',\n",
       " 'that',\n",
       " 'may',\n",
       " 'be',\n",
       " 'based',\n",
       " 'on',\n",
       " 'incomplete',\n",
       " 'or',\n",
       " 'inaccurate',\n",
       " 'information',\n",
       " '.',\n",
       " 'Ultimately',\n",
       " ',',\n",
       " 'this',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'more',\n",
       " 'positive',\n",
       " 'and',\n",
       " 'productive',\n",
       " 'interactions',\n",
       " 'with',\n",
       " 'others',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'Bdvantages',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'in',\n",
       " 'Everyday',\n",
       " 'Life',\n",
       " 'Technology',\n",
       " 'has',\n",
       " 'become',\n",
       " 'an',\n",
       " 'integral',\n",
       " 'part',\n",
       " 'of',\n",
       " 'our',\n",
       " 'lives',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'has',\n",
       " 'brought',\n",
       " 'numerous',\n",
       " 'advantages',\n",
       " 'to',\n",
       " 'our',\n",
       " 'everyday',\n",
       " 'lives',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'advantages',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'connect',\n",
       " 'people',\n",
       " 'from',\n",
       " 'different',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'advent',\n",
       " 'of',\n",
       " 'social',\n",
       " 'media',\n",
       " 'and',\n",
       " 'video',\n",
       " 'conferencing',\n",
       " ',',\n",
       " 'people',\n",
       " 'can',\n",
       " 'now',\n",
       " 'communicate',\n",
       " 'with',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'family',\n",
       " 'members',\n",
       " 'from',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Bnother',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'make',\n",
       " 'our',\n",
       " 'lives',\n",
       " 'easier',\n",
       " 'and',\n",
       " 'more',\n",
       " 'convenient',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'online',\n",
       " 'shopping',\n",
       " 'and',\n",
       " 'banking',\n",
       " 'have',\n",
       " 'made',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'do',\n",
       " 'our',\n",
       " 'shopping',\n",
       " 'and',\n",
       " 'banking',\n",
       " 'from',\n",
       " 'the',\n",
       " 'comfort',\n",
       " 'of',\n",
       " 'our',\n",
       " 'own',\n",
       " 'homes',\n",
       " '.',\n",
       " 'Bdditionally',\n",
       " ',',\n",
       " 'technology',\n",
       " 'has',\n",
       " 'made',\n",
       " 'it',\n",
       " 'easier',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'access',\n",
       " 'information',\n",
       " ',',\n",
       " 'whether',\n",
       " 'it',\n",
       " 'be',\n",
       " 'through',\n",
       " 'search',\n",
       " 'engines',\n",
       " 'or',\n",
       " 'online',\n",
       " 'databases',\n",
       " '.',\n",
       " 'Technology',\n",
       " 'has',\n",
       " 'also',\n",
       " 'revolutionized',\n",
       " 'the',\n",
       " 'way',\n",
       " 'we',\n",
       " 'work',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'remote',\n",
       " 'work',\n",
       " 'and',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'collaborate',\n",
       " 'online',\n",
       " ',',\n",
       " 'employees',\n",
       " 'can',\n",
       " 'now',\n",
       " 'work',\n",
       " 'from',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'This',\n",
       " 'has',\n",
       " 'led',\n",
       " 'to',\n",
       " 'an',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'productivity',\n",
       " 'and',\n",
       " 'job',\n",
       " 'satisfaction',\n",
       " '.',\n",
       " 'Potential',\n",
       " 'Misuse',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'in',\n",
       " 'Everyday',\n",
       " 'Matters',\n",
       " 'While',\n",
       " 'technology',\n",
       " 'has',\n",
       " 'brought',\n",
       " 'numerous',\n",
       " 'advantages',\n",
       " 'to',\n",
       " 'our',\n",
       " 'lives',\n",
       " ',',\n",
       " 'it',\n",
       " 'has',\n",
       " 'also',\n",
       " 'brought',\n",
       " 'potential',\n",
       " 'misuse',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'potential',\n",
       " 'misuses',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'be',\n",
       " 'addictive',\n",
       " '.',\n",
       " 'Social',\n",
       " 'media',\n",
       " ',',\n",
       " 'video',\n",
       " 'games',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'forms',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'can',\n",
       " 'become',\n",
       " 'all',\n",
       " 'consuming',\n",
       " ',',\n",
       " 'leading',\n",
       " 'to',\n",
       " 'a',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'productivity',\n",
       " 'and',\n",
       " 'social',\n",
       " 'isolation',\n",
       " '.',\n",
       " 'Bnother',\n",
       " 'potential',\n",
       " 'misuse',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'be',\n",
       " 'used',\n",
       " 'for',\n",
       " 'cyberbullying',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'social',\n",
       " 'media',\n",
       " ',',\n",
       " 'cyberbullying',\n",
       " 'has',\n",
       " 'become',\n",
       " 'more',\n",
       " 'prevalent',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'can',\n",
       " 'have',\n",
       " 'severe',\n",
       " 'consequences',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'of',\n",
       " 'the',\n",
       " 'victim',\n",
       " '.',\n",
       " 'Potential',\n",
       " 'Negative',\n",
       " 'Effects',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'on',\n",
       " 'the',\n",
       " 'New',\n",
       " 'Generation',\n",
       " 'While',\n",
       " 'technology',\n",
       " 'has',\n",
       " 'brought',\n",
       " 'numerous',\n",
       " 'advantages',\n",
       " 'to',\n",
       " 'our',\n",
       " 'lives',\n",
       " ',',\n",
       " 'it',\n",
       " 'has',\n",
       " 'also',\n",
       " 'had',\n",
       " 'potential',\n",
       " 'negative',\n",
       " 'effects',\n",
       " 'on',\n",
       " 'the',\n",
       " 'new',\n",
       " 'generation',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'potential',\n",
       " 'negative',\n",
       " 'effects',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'a',\n",
       " 'decrease',\n",
       " 'in',\n",
       " 'facetoface',\n",
       " 'communication',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'social',\n",
       " 'media',\n",
       " 'and',\n",
       " 'messaging',\n",
       " 'apps',\n",
       " ',',\n",
       " 'people',\n",
       " 'are',\n",
       " 'increasingly',\n",
       " 'relying',\n",
       " 'on',\n",
       " 'technology',\n",
       " 'to',\n",
       " 'communicate',\n",
       " 'with',\n",
       " 'others',\n",
       " ',',\n",
       " 'leading',\n",
       " 'to',\n",
       " 'a',\n",
       " 'decrease',\n",
       " 'in',\n",
       " 'facetoface',\n",
       " 'communication',\n",
       " '.',\n",
       " 'Bnother',\n",
       " 'potential',\n",
       " 'negative',\n",
       " 'effect',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'a',\n",
       " 'decrease',\n",
       " 'in',\n",
       " 'attention',\n",
       " 'span',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'constant',\n",
       " 'influx',\n",
       " 'of',\n",
       " 'information',\n",
       " 'and',\n",
       " 'entertainment',\n",
       " 'available',\n",
       " 'through',\n",
       " 'technology',\n",
       " ',',\n",
       " 'people',\n",
       " 'are',\n",
       " 'becoming',\n",
       " 'increasingly',\n",
       " 'distracted',\n",
       " 'and',\n",
       " 'have',\n",
       " 'a',\n",
       " 'shorter',\n",
       " 'attention',\n",
       " 'span',\n",
       " '.',\n",
       " 'Impact',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'on',\n",
       " 'Business',\n",
       " 'Operations',\n",
       " 'Technology',\n",
       " 'has',\n",
       " 'had',\n",
       " 'a',\n",
       " 'significant',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'business',\n",
       " 'Competition',\n",
       " 'for',\n",
       " 'high',\n",
       " 'grades',\n",
       " 'is',\n",
       " 'an',\n",
       " 'issue',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'widely',\n",
       " 'debated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'educational',\n",
       " 'system',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'believed',\n",
       " 'that',\n",
       " 'competition',\n",
       " 'for',\n",
       " 'high',\n",
       " 'grades',\n",
       " 'forces',\n",
       " 'students',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'more',\n",
       " 'on',\n",
       " 'grades',\n",
       " 'than',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'their',\n",
       " 'learning',\n",
       " '.',\n",
       " 'While',\n",
       " 'the',\n",
       " 'competition',\n",
       " 'for',\n",
       " 'high',\n",
       " 'grades',\n",
       " 'can',\n",
       " 'be',\n",
       " 'beneficial',\n",
       " 'in',\n",
       " 'some',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'learning',\n",
       " ',',\n",
       " 'it',\n",
       " 'can',\n",
       " 'also',\n",
       " 'have',\n",
       " 'a',\n",
       " 'negative',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'the',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'learning',\n",
       " 'at',\n",
       " 'all',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'education',\n",
       " '.',\n",
       " 'On',\n",
       " 'the',\n",
       " 'one',\n",
       " 'hand',\n",
       " ',',\n",
       " 'competition',\n",
       " 'for',\n",
       " 'high',\n",
       " 'grades',\n",
       " 'is',\n",
       " 'often',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'beneficial',\n",
       " 'in',\n",
       " 'some',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'learning',\n",
       " '.',\n",
       " 'For',\n",
       " 'example',\n",
       " ',',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'higher',\n",
       " 'grades',\n",
       " ',',\n",
       " 'students',\n",
       " 'may',\n",
       " 'be',\n",
       " 'incentivized',\n",
       " 'to',\n",
       " 'work',\n",
       " 'harder',\n",
       " 'and',\n",
       " 'put',\n",
       " 'in',\n",
       " 'extra',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'they',\n",
       " 'are',\n",
       " 'achieving',\n",
       " 'their',\n",
       " 'best',\n",
       " 'work',\n",
       " '.',\n",
       " 'This',\n",
       " 'can',\n",
       " 'be',\n",
       " 'seen',\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = tokens_ia\n",
    "\n",
    "def pos_tagged_words(tagged_sents):\n",
    "    tagged_words = []\n",
    "    for sent in tagged_sents:\n",
    "        for word in sent:\n",
    "            tagged_words.append(word)\n",
    "    return tagged_words\n",
    "\n",
    "tagged_words = pos_tagged_words(tagged_sents)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852d3b8",
   "metadata": {},
   "source": [
    "### Finding the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c877fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 20338),\n",
       " ('.', 19864),\n",
       " (',', 15631),\n",
       " ('to', 14626),\n",
       " ('a', 10206),\n",
       " ('and', 9516),\n",
       " ('of', 7837),\n",
       " ('that', 7276),\n",
       " ('in', 6965),\n",
       " ('is', 6413),\n",
       " ('it', 6145),\n",
       " ('you', 5553),\n",
       " ('they', 4764),\n",
       " ('be', 4665),\n",
       " ('for', 4570),\n",
       " ('have', 3904),\n",
       " ('are', 3716),\n",
       " ('i', 3504),\n",
       " ('on', 3160),\n",
       " ('not', 3088)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list =[]\n",
    "for i in range(len(tokens_human)):\n",
    "    for w in tokens_human[i]:\n",
    "        list.append(w.lower())\n",
    "    \n",
    "fdist_human = nltk.FreqDist(list)\n",
    "fdist_human.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dece973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 20261),\n",
       " ('.', 17113),\n",
       " ('the', 14041),\n",
       " ('and', 11632),\n",
       " ('to', 11623),\n",
       " ('of', 8333),\n",
       " ('a', 7976),\n",
       " ('in', 6243),\n",
       " ('that', 4857),\n",
       " ('is', 4184),\n",
       " ('for', 4048),\n",
       " ('it', 3861),\n",
       " ('can', 3787),\n",
       " ('are', 2660),\n",
       " ('i', 2595),\n",
       " ('be', 2562),\n",
       " ('on', 2467),\n",
       " ('this', 2342),\n",
       " ('their', 2324),\n",
       " ('with', 2128)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list =[]\n",
    "for i in range(len(tokens_ia)):\n",
    "    for w in tokens_ia[i]:\n",
    "        list.append(w.lower())\n",
    "    \n",
    "fdist_ia = nltk.FreqDist(list)\n",
    "fdist_ia.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "995b029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('students', 1965),\n",
       " ('people', 1487),\n",
       " ('also', 1233),\n",
       " ('electoral', 1164),\n",
       " ('help', 1071),\n",
       " ('may', 1047),\n",
       " ('college', 1035),\n",
       " ('like', 1019),\n",
       " ('make', 900),\n",
       " ('cars', 875),\n",
       " ('car', 870),\n",
       " ('school', 862),\n",
       " ('one', 853),\n",
       " ('time', 851),\n",
       " ('important', 836),\n",
       " ('states', 784),\n",
       " ('would', 770),\n",
       " ('could', 768),\n",
       " ('many', 729),\n",
       " ('life', 698)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_tok_ia = []\n",
    "\n",
    "for token_list in tokens_ia:\n",
    "    for token in token_list:\n",
    "\n",
    "        token = token.lower()\n",
    "        \n",
    "        token = token.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        if token and token not in stop_words:\n",
    "            filtered_tok_ia.append(token)\n",
    "\n",
    "fdist_ia = FreqDist(filtered_tok_ia)\n",
    "fdist_ia.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df53d99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('students', 3048),\n",
       " ('people', 2947),\n",
       " ('would', 2883),\n",
       " ('nt', 2404),\n",
       " ('school', 1849),\n",
       " ('could', 1516),\n",
       " ('car', 1488),\n",
       " ('get', 1425),\n",
       " ('like', 1376),\n",
       " ('cars', 1367),\n",
       " ('also', 1342),\n",
       " ('student', 1256),\n",
       " ('time', 1201),\n",
       " ('think', 1184),\n",
       " ('one', 1177),\n",
       " ('electoral', 1144),\n",
       " ('help', 1125),\n",
       " ('make', 1115),\n",
       " ('many', 1115),\n",
       " ('college', 996)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_tok_human = []\n",
    "\n",
    "for token_list in tokens_human:\n",
    "    for token in token_list:\n",
    "\n",
    "        token = token.lower()\n",
    "        \n",
    "        token = token.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        if token and token not in stop_words:\n",
    "            filtered_tok_human.append(token)\n",
    "\n",
    "fdist_human = FreqDist(filtered_tok_human)\n",
    "fdist_human.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e8e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

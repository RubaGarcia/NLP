{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580020c4-bdd1-475b-afa6-4e3bf8eaeac5",
   "metadata": {},
   "source": [
    "Comienzo de la pr√°ctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a09d96c9-5ae2-4d9a-bb39-7d3ec651e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd #procesado del csv pasa E/S\n",
    "import matplotlib as plt #printeo\n",
    "import random #operaciones matematicas\n",
    "from metodos import * #importamos metodos para una mayor legibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/Temas.txt\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/notebook_final.ipynb\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/prueba.py\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/archive/AI_Human.csv\n",
      "/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/.ipynb_checkpoints/notebook_final-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "for dirname, _, filenames in os.walk('/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d92929-910d-40c3-ad20-0ebf319a24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = pd.read_csv('/home/ubuntu/Escritorio/repos/segundo-cuatri/NLP/NLP-practicas_grupo/proyecto-final/archive/AI_Human.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e087b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos totales:  487235\n",
      "Humanos:  305797\n",
      "IA:  181438\n"
     ]
    }
   ],
   "source": [
    "datos_totales = (datos['generated']).count()\n",
    "datos_humanos = (datos['generated'] == 0.0).sum()\n",
    "print(\"Datos totales: \", datos_totales)\n",
    "print(\"Humanos: \", datos_humanos)\n",
    "print(\"IA: \", datos_totales - datos_humanos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d189d61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cars',\n",
       " '.',\n",
       " 'Cars',\n",
       " 'have',\n",
       " 'been',\n",
       " 'around',\n",
       " 'since',\n",
       " 'they',\n",
       " 'became',\n",
       " 'famous',\n",
       " 'in',\n",
       " 'the',\n",
       " '1900s',\n",
       " ',',\n",
       " 'when',\n",
       " 'Henry',\n",
       " 'Ford',\n",
       " 'created',\n",
       " 'and',\n",
       " 'built',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ModelT',\n",
       " '.',\n",
       " 'Cars',\n",
       " 'have',\n",
       " 'played',\n",
       " 'a',\n",
       " 'major',\n",
       " 'role',\n",
       " 'in',\n",
       " 'our',\n",
       " 'every',\n",
       " 'day',\n",
       " 'lives',\n",
       " 'since',\n",
       " 'then',\n",
       " '.',\n",
       " 'But',\n",
       " 'now',\n",
       " ',',\n",
       " 'people',\n",
       " 'are',\n",
       " 'starting',\n",
       " 'to',\n",
       " 'question',\n",
       " 'if',\n",
       " 'limiting',\n",
       " 'car',\n",
       " 'usage',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " '.',\n",
       " 'To',\n",
       " 'me',\n",
       " ',',\n",
       " 'limiting',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cars',\n",
       " 'might',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'do',\n",
       " '.',\n",
       " 'In',\n",
       " 'like',\n",
       " 'matter',\n",
       " 'of',\n",
       " 'this',\n",
       " ',',\n",
       " 'article',\n",
       " ',',\n",
       " '``',\n",
       " 'In',\n",
       " 'German',\n",
       " 'Suburb',\n",
       " ',',\n",
       " 'Life',\n",
       " 'Goes',\n",
       " 'On',\n",
       " 'Without',\n",
       " 'Cars',\n",
       " ',',\n",
       " \"''\",\n",
       " 'by',\n",
       " 'Elizabeth',\n",
       " 'Rosenthal',\n",
       " 'states',\n",
       " ',',\n",
       " 'how',\n",
       " 'automobiles',\n",
       " 'are',\n",
       " 'the',\n",
       " 'linchpin',\n",
       " 'of',\n",
       " 'suburbs',\n",
       " ',',\n",
       " 'where',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'families',\n",
       " 'from',\n",
       " 'either',\n",
       " 'Shanghai',\n",
       " 'or',\n",
       " 'Chicago',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'make',\n",
       " 'their',\n",
       " 'homes',\n",
       " '.',\n",
       " 'Experts',\n",
       " 'say',\n",
       " 'how',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'impediment',\n",
       " 'to',\n",
       " 'current',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'reduce',\n",
       " 'greenhouse',\n",
       " 'gas',\n",
       " 'emissions',\n",
       " 'from',\n",
       " 'tailpipe',\n",
       " '.',\n",
       " 'Passenger',\n",
       " 'cars',\n",
       " 'are',\n",
       " 'responsible',\n",
       " 'for',\n",
       " '12',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'greenhouse',\n",
       " 'gas',\n",
       " 'emissions',\n",
       " 'in',\n",
       " 'Europe',\n",
       " '...',\n",
       " 'and',\n",
       " 'up',\n",
       " 'to',\n",
       " '50',\n",
       " 'percent',\n",
       " 'in',\n",
       " 'some',\n",
       " 'carintensive',\n",
       " 'areas',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " '.',\n",
       " 'Cars',\n",
       " 'are',\n",
       " 'the',\n",
       " 'main',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'the',\n",
       " 'greenhouse',\n",
       " 'gas',\n",
       " 'emissions',\n",
       " 'because',\n",
       " 'of',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'people',\n",
       " 'driving',\n",
       " 'them',\n",
       " 'around',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " 'getting',\n",
       " 'where',\n",
       " 'they',\n",
       " 'need',\n",
       " 'to',\n",
       " 'go',\n",
       " '.',\n",
       " 'Article',\n",
       " ',',\n",
       " '``',\n",
       " 'Paris',\n",
       " 'bans',\n",
       " 'driving',\n",
       " 'due',\n",
       " 'to',\n",
       " 'smog',\n",
       " ',',\n",
       " \"''\",\n",
       " 'by',\n",
       " 'Robert',\n",
       " 'Duffer',\n",
       " 'says',\n",
       " ',',\n",
       " 'how',\n",
       " 'Paris',\n",
       " ',',\n",
       " 'after',\n",
       " 'days',\n",
       " 'of',\n",
       " 'nearrecord',\n",
       " 'pollution',\n",
       " ',',\n",
       " 'enforced',\n",
       " 'a',\n",
       " 'partial',\n",
       " 'driving',\n",
       " 'ban',\n",
       " 'to',\n",
       " 'clear',\n",
       " 'the',\n",
       " 'air',\n",
       " 'of',\n",
       " 'the',\n",
       " 'global',\n",
       " 'city',\n",
       " '.',\n",
       " 'It',\n",
       " 'also',\n",
       " 'says',\n",
       " ',',\n",
       " 'how',\n",
       " 'on',\n",
       " 'Monday',\n",
       " ',',\n",
       " 'motorist',\n",
       " 'with',\n",
       " 'evennumbered',\n",
       " 'license',\n",
       " 'plates',\n",
       " 'were',\n",
       " 'ordered',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'their',\n",
       " 'cars',\n",
       " 'at',\n",
       " 'home',\n",
       " 'or',\n",
       " 'be',\n",
       " 'fined',\n",
       " 'a',\n",
       " '22euro',\n",
       " 'fine',\n",
       " '31',\n",
       " '.',\n",
       " 'The',\n",
       " 'same',\n",
       " 'order',\n",
       " 'would',\n",
       " 'be',\n",
       " 'applied',\n",
       " 'to',\n",
       " 'oddnumbered',\n",
       " 'plates',\n",
       " 'the',\n",
       " 'following',\n",
       " 'day',\n",
       " '.',\n",
       " 'Cars',\n",
       " 'are',\n",
       " 'the',\n",
       " 'reason',\n",
       " 'for',\n",
       " 'polluting',\n",
       " 'entire',\n",
       " 'cities',\n",
       " 'like',\n",
       " 'Paris',\n",
       " '.',\n",
       " 'This',\n",
       " 'shows',\n",
       " 'how',\n",
       " 'bad',\n",
       " 'cars',\n",
       " 'can',\n",
       " 'be',\n",
       " 'because',\n",
       " ',',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'pollution',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'cause',\n",
       " 'to',\n",
       " 'an',\n",
       " 'entire',\n",
       " 'city',\n",
       " '.',\n",
       " 'Likewise',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'article',\n",
       " ',',\n",
       " '``',\n",
       " 'Carfree',\n",
       " 'day',\n",
       " 'is',\n",
       " 'spinning',\n",
       " 'into',\n",
       " 'a',\n",
       " 'big',\n",
       " 'hit',\n",
       " 'in',\n",
       " 'Bogota',\n",
       " ',',\n",
       " \"''\",\n",
       " 'by',\n",
       " 'Andrew',\n",
       " 'Selsky',\n",
       " 'says',\n",
       " ',',\n",
       " 'how',\n",
       " 'programs',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'set',\n",
       " 'to',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'other',\n",
       " 'countries',\n",
       " ',',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'Columbians',\n",
       " 'hiked',\n",
       " ',',\n",
       " 'biked',\n",
       " ',',\n",
       " 'skated',\n",
       " ',',\n",
       " 'or',\n",
       " 'took',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'to',\n",
       " 'work',\n",
       " 'during',\n",
       " 'a',\n",
       " 'carfree',\n",
       " 'day',\n",
       " ',',\n",
       " 'leaving',\n",
       " 'streets',\n",
       " 'of',\n",
       " 'this',\n",
       " 'capital',\n",
       " 'city',\n",
       " 'eerily',\n",
       " 'devoid',\n",
       " 'of',\n",
       " 'traffic',\n",
       " 'jams',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'the',\n",
       " 'third',\n",
       " 'straight',\n",
       " 'year',\n",
       " 'cars',\n",
       " 'have',\n",
       " 'been',\n",
       " 'banned',\n",
       " 'with',\n",
       " 'only',\n",
       " 'buses',\n",
       " 'and',\n",
       " 'taxis',\n",
       " 'permitted',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Day',\n",
       " 'Without',\n",
       " 'Cars',\n",
       " 'in',\n",
       " 'the',\n",
       " 'capital',\n",
       " 'city',\n",
       " 'of',\n",
       " '7',\n",
       " 'million',\n",
       " '.',\n",
       " 'People',\n",
       " 'like',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'having',\n",
       " 'carfree',\n",
       " 'days',\n",
       " 'because',\n",
       " ',',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'them',\n",
       " 'to',\n",
       " 'lesson',\n",
       " 'the',\n",
       " 'pollution',\n",
       " 'that',\n",
       " 'cars',\n",
       " 'put',\n",
       " 'out',\n",
       " 'of',\n",
       " 'their',\n",
       " 'exhaust',\n",
       " 'from',\n",
       " 'people',\n",
       " 'driving',\n",
       " 'all',\n",
       " 'the',\n",
       " 'time',\n",
       " '.',\n",
       " 'The',\n",
       " 'article',\n",
       " 'also',\n",
       " 'tells',\n",
       " 'how',\n",
       " 'parks',\n",
       " 'and',\n",
       " 'sports',\n",
       " 'centers',\n",
       " 'have',\n",
       " 'bustled',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'city',\n",
       " 'uneven',\n",
       " ',',\n",
       " 'pitted',\n",
       " 'sidewalks',\n",
       " 'have',\n",
       " 'been',\n",
       " 'replaced',\n",
       " 'by',\n",
       " 'broad',\n",
       " ',',\n",
       " 'smooth',\n",
       " 'sidewalks',\n",
       " 'rushhour',\n",
       " 'restrictions',\n",
       " 'have',\n",
       " 'dramatically',\n",
       " 'cut',\n",
       " 'traffic',\n",
       " 'and',\n",
       " 'new',\n",
       " 'restaurants',\n",
       " 'and',\n",
       " 'upscale',\n",
       " 'shopping',\n",
       " 'districts',\n",
       " 'have',\n",
       " 'cropped',\n",
       " 'up',\n",
       " '.',\n",
       " 'Having',\n",
       " 'no',\n",
       " 'cars',\n",
       " 'has',\n",
       " 'been',\n",
       " 'good',\n",
       " 'for',\n",
       " 'the',\n",
       " 'country',\n",
       " 'of',\n",
       " 'Columbia',\n",
       " 'because',\n",
       " ',',\n",
       " 'it',\n",
       " 'has',\n",
       " 'aloud',\n",
       " 'them',\n",
       " 'to',\n",
       " 'repair',\n",
       " 'things',\n",
       " 'that',\n",
       " 'have',\n",
       " 'needed',\n",
       " 'repairs',\n",
       " 'for',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " ',',\n",
       " 'traffic',\n",
       " 'jams',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'down',\n",
       " ',',\n",
       " 'and',\n",
       " 'restaurants',\n",
       " 'and',\n",
       " 'shopping',\n",
       " 'districts',\n",
       " 'have',\n",
       " 'popped',\n",
       " 'up',\n",
       " ',',\n",
       " 'all',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'of',\n",
       " 'having',\n",
       " 'less',\n",
       " 'cars',\n",
       " 'around',\n",
       " '.',\n",
       " 'In',\n",
       " 'conclusion',\n",
       " ',',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'less',\n",
       " 'cars',\n",
       " 'and',\n",
       " 'having',\n",
       " 'carfree',\n",
       " 'days',\n",
       " ',',\n",
       " 'have',\n",
       " 'had',\n",
       " 'a',\n",
       " 'big',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'the',\n",
       " 'environment',\n",
       " 'of',\n",
       " 'cities',\n",
       " 'because',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'cutting',\n",
       " 'down',\n",
       " 'the',\n",
       " 'air',\n",
       " 'pollution',\n",
       " 'that',\n",
       " 'the',\n",
       " 'cars',\n",
       " 'have',\n",
       " 'majorly',\n",
       " 'polluted',\n",
       " ',',\n",
       " 'it',\n",
       " 'has',\n",
       " 'aloud',\n",
       " 'countries',\n",
       " 'like',\n",
       " 'Columbia',\n",
       " 'to',\n",
       " 'repair',\n",
       " 'sidewalks',\n",
       " ',',\n",
       " 'and',\n",
       " 'cut',\n",
       " 'down',\n",
       " 'traffic',\n",
       " 'jams',\n",
       " '.',\n",
       " 'Limiting',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cars',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'for',\n",
       " 'America',\n",
       " '.',\n",
       " 'So',\n",
       " 'we',\n",
       " 'should',\n",
       " 'limit',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cars',\n",
       " 'by',\n",
       " 'maybe',\n",
       " 'riding',\n",
       " 'a',\n",
       " 'bike',\n",
       " ',',\n",
       " 'or',\n",
       " 'maybe',\n",
       " 'walking',\n",
       " 'somewhere',\n",
       " 'that',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'that',\n",
       " 'far',\n",
       " 'from',\n",
       " 'you',\n",
       " 'and',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'a',\n",
       " 'car',\n",
       " 'to',\n",
       " 'get',\n",
       " 'you',\n",
       " 'there',\n",
       " '.',\n",
       " 'To',\n",
       " 'me',\n",
       " ',',\n",
       " 'limiting',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cars',\n",
       " 'might',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'do',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nltk.word_tokenize(datos['text'][0])\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dda7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ia = []\n",
    "tokens_human = []\n",
    "i = (len(datos['text'])//20)\n",
    "while i > 0:\n",
    "    valor = random.randint(0, len(datos['text']))\n",
    "    token = nltk.word_tokenize(datos['text'][valor])\n",
    "    if datos['generated'][i] == 1.0:\n",
    "        tokens_ia.append(token)\n",
    "    else:\n",
    "        tokens_human.append(token)\n",
    "    i -= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61848e",
   "metadata": {},
   "source": [
    "Let's find the lexical richness of the AI texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3ef7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43716589809480083"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_richness_ia = 0\n",
    "num = 0\n",
    "for i in range(0, len(tokens_ia)):\n",
    "    medium_richness_ia += lexical_richness(tokens_ia[i])\n",
    "    num += 1\n",
    "medium_richness_ia = medium_richness_ia/num\n",
    "medium_richness_ia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede1bc3",
   "metadata": {},
   "source": [
    "Let's find the lexical richness of the Human texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2bfdc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43796917386058304"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_richness_human = 0\n",
    "num = 0\n",
    "for i in range(0, len(tokens_human)):\n",
    "    medium_richness_human += lexical_richness(tokens_human[i])\n",
    "    num += 1\n",
    "medium_richness_human = medium_richness_human/num\n",
    "medium_richness_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7755cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
